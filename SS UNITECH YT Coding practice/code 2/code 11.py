# Databricks notebook source
# Input Table:
# | user_id | date       |
# | ------: | ---------- |
# |       1 | 2024-01-05 |
# |       2 | 2024-01-10 |
# |       3 | 2024-01-15 |
# |       1 | 2024-02-01 |
# |       4 | 2024-02-11 |
# |       5 | 2024-02-18 |
# |       6 | 2024-02-28 |
# |       7 | 2024-03-05 |
# |       8 | 2024-03-10 |
# |       9 | 2024-03-15 |
# |      10 | 2024-04-02 |
# |      11 | 2024-04-05 |
# |      12 | 2024-04-10 |
# |      13 | 2024-05-01 |
# |      14 | 2024-05-06 |
# |      15 | 2024-05-10 |

# Output Table

# | month | user_count | perc_change |
# | ----: | ---------: | ----------: |
# |     1 |          3 |        NULL |
# |     2 |          4 |       33.33 |
# |     3 |          3 |      -25.00 |
# |     4 |          3 |        0.00 |
# |     5 |          3 |        0.00 |

from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

data = [
    (1, "2024-01-05"),
    (2, "2024-01-10"),
    (3, "2024-01-15"),
    (1, "2024-02-01"),
    (4, "2024-02-11"),
    (5, "2024-02-18"),
    (6, "2024-02-28"),
    (7, "2024-03-05"),
    (8, "2024-03-10"),
    (9, "2024-03-15"),
    (10, "2024-04-02"),
    (11, "2024-04-05"),
    (12, "2024-04-10"),
    (13, "2024-05-01"),
    (14, "2024-05-06"),
    (15, "2024-05-10")
]

columns = ["user_id", "date"]

df_users = spark.createDataFrame(data, columns)



